================================================================================
INSTRUCTIONS FOR COMPUTER 2 - WALMART SCRAPER
================================================================================

STEP 1: Copy These Files to Computer 2
----------------------------------------
Copy the entire "webscraping tool" folder to Computer 2, including:
  - scrape_walmart_parallel.py
  - scrapers/ folder (entire folder)
  - config.py
  - WebsiteScrapper 2.ods
  - unique_unscraped_rows_computer2.txt (IMPORTANT: Use this file!)
  - start_scraper_computer2.bat (or use the command below)

STEP 2: Install Dependencies (if not already installed)
--------------------------------------------------------
On Computer 2, open Command Prompt and run:
  pip install pandas openpyxl odfpy selenium beautifulsoup4 undetected-chromedriver

STEP 3: Start the Scraper
--------------------------
Option A - Double-click: start_scraper_computer2.bat

Option B - Command Line:
  cd "C:\path\to\webscraping tool"
  python scrape_walmart_parallel.py --spreadsheet "WebsiteScrapper 2.ods" --row-numbers-file "unique_unscraped_rows_computer2.txt" --workers 2 --flush-size 5 --output-file "walmart_scraped_products_computer2.json"

STEP 4: Monitor Progress
------------------------
The scraper will:
  - Save results to: walmart_scraped_products_computer2.json
  - Create backups in: backups/ folder
  - Show progress in the console

STEP 5: When Finished
---------------------
After Computer 2 finishes scraping:
  1. Copy walmart_scraped_products_computer2.json to Computer 1
  2. On Computer 1, run: python merge_results_from_two_computers.py
  3. Follow the prompts to merge the results

================================================================================
IMPORTANT NOTES
================================================================================
- Output file: walmart_scraped_products_computer2.json (different from Computer 1)
- Row numbers file: unique_unscraped_rows_computer2.txt (IMPORTANT!)
- The scraper will automatically create backups
- The scraper will skip already-scraped products
- You can stop and restart anytime - it will continue from where it left off

================================================================================
QUICK COMMAND (Copy and paste this on Computer 2)
================================================================================

python scrape_walmart_parallel.py --spreadsheet "WebsiteScrapper 2.ods" --row-numbers-file "unique_unscraped_rows_computer2.txt" --workers 2 --flush-size 5 --output-file "walmart_scraped_products_computer2.json"

================================================================================

